# Chapter 9
# Introduction

As digital technology has advanced, more academic papers and historical documents have been saved and shared in PDF format, which has provided researchers with a large collection of resources. However, as these collections have grown, the need to extract key information, or metadata, from each document has become important. Metadata contains essential details, such as the author, title, publication date, and keywords, which help people organize, search, and archive content. The ability to automate metadata extraction has allowed people to make this process faster and more consistent, especially for large volumes of data.

Over the years, different methods have been developed for extracting metadata, including rule-based approaches, machine learning, deep learning, hybrid models, and specialized tools. Each technique has offered specific advantages and faced challenges when people have applied it to different types of documents. People have found that rule-based methods perform well with structured documents, although they often fail when used with more varied ones. People have used machine learning and deep learning approaches to handle complex document structures. Still, they have found that these methods require a large amount of labeled data and high computational power. Researchers have also turned to hybrid methods and specialized tools, such as GROBID and CERMINE, which offer a combination of flexibility and accuracy to make them useful for handling a wider range of document formats.

In this project, our goal is to create a digital archive of metadata for documents that focus on the American feminist movement. Because our project works with text-based PDF documents and does not involve converting images to text, we chose GROBID as our primary tool for metadata extraction. GROBID has provided support for batch processing, offered API access, and shown compatibility with different document formats, which makes it a good choice for managing large sets of data in this project.

## Related work

In the field of metadata extraction, researchers have explored different methods that aim to improve accuracy and ease of use. These methods fall into four main categories: rule-based methods, machine learning and deep learning methods, hybrid models, and specialized tools.

Rule-based methods rely on keywords and structural patterns so that metadata can be identified within documents. Alyami et al. (2023) combined Support Vector Machines (SVM) with rule-based methods so that they could achieve higher accuracy in structured documents, while Cortez et al. (2009) developed a system that used patterns so that metadata could be extracted from academic papers. Rule-based methods work best when documents follow a consistent format, although these methods do not perform well with more complex layouts (Alyami et al., 2023; Cortez et al., 2009). Another study presented a rule-based approach for extracting metadata from scientific PDFs, which is highly effective when used with standard document formats (Rule-Based Metadata Extraction, 2020).

Machine learning and deep learning methods allow for handling more complex document structures. Cortez et al. (2009) showed that machine learning models can adapt to various document layouts, while Khan et al. (2023) used a bi-directional LSTM model so that metadata could be extracted from multilingual news archives, which often contain documents with looser structures (Cortez et al., 2009; Khan et al., 2023). Raghavendra Nayaka and Ranjan (2023) applied deep neural networks so that they could extract metadata from academic texts, achieving high accuracy especially in scientific articles, making this approach useful for structured data ￼.

Hybrid methods integrate rule-based and machine learning approaches so that they can work with a variety of document layouts. Wankhade et al. (2022) proposed a model that combines rules with SVM so that it can handle complex layouts, and Chang et al. (2020) introduced optimization algorithms and feature selection to improve the results from hybrid methods. These approaches offer stable results even when used with smaller datasets, making them suitable for projects that involve extracting metadata from different document formats (Chang et al., 2020; Wankhade et al., 2022).

Specialized tools like GROBID and CERMINE support metadata extraction for large datasets. Researchers often choose GROBID in academic work because it supports batch processing and includes an API that can handle structured PDFs (GROBID team, 2020). CERMINE uses conditional random fields so that metadata can be extracted from journal articles, and it performs well with standardized document formats (Tkaczyk et al., 2015). The primer “Understanding Metadata: What is Metadata” (2017) provides information about metadata standards such as Dublin Core, which are helpful when structuring metadata. Compared to CERMINE, GROBID provides greater flexibility across document formats, making it an ideal tool for broad metadata extraction tasks (GROBID team, 2020; Tkaczyk et al., 2015).

In summary, research shows that rule-based methods are more suitable for structured documents, while machine learning and deep learning methods are better for complex formats. Hybrid methods combine these strengths so that they are adaptable across various layouts. Tools like GROBID, which support batch processing and provide API access, are highly suitable for handling diverse document types. This makes GROBID an excellent choice for our project, where we seek to build a detailed metadata archive for U.S. feminist literature.
